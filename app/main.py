import sys
import os

# Asegurar que Python encuentra el m칩dulo core
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

import streamlit as st
from core.watsonx_llm import WatsonxLLM
from core.data_input import get_consumo_simulado  # Funci칩n para obtener datos simulados

# Configuraci칩n de la app
st.set_page_config(page_title="DeepWater", layout="wide")

st.title("游눦 DeepWater - Optimiza tu consumo de agua")

# Inicializar Watsonx
llm = WatsonxLLM()

# Inicializar estado de datos si a칰n no existe
if "datos_consumo" not in st.session_state:
    st.session_state["datos_consumo"] = None

if "analisis_consumo" not in st.session_state:
    st.session_state["analisis_consumo"] = None

# Bot칩n para analizar consumo de agua
if st.button("游뛇 Analiza mi consumo de agua"):
    with st.spinner("Analizando tu consumo..."):
        datos_consumo = get_consumo_simulado()  # Obtener datos simulados
        st.session_state["datos_consumo"] = datos_consumo  # Guardar datos en sesi칩n

        prompt_analisis = f"""
        Datos del hogar: {datos_consumo}

        Asistente:
        Analiza estos datos y proporciona un diagn칩stico con recomendaciones pr치cticas para ahorrar agua.
        Responde en un m치ximo de 3 frases o en una lista de puntos.
        """
        respuesta_analisis = llm.invoke(prompt_analisis)
        st.session_state["analisis_consumo"] = respuesta_analisis  # Guardar an치lisis

    st.subheader("游댌 An치lisis del consumo de agua")
    st.markdown(respuesta_analisis)

# Mostrar an치lisis si ya fue realizado
if st.session_state["analisis_consumo"]:
    st.subheader("游댌 An치lisis del consumo de agua")
    st.markdown(st.session_state["analisis_consumo"])

# Secci칩n de Chat
st.subheader("游눫 Consulta sobre ahorro de agua")

# Inicializar historial de chat
if "messages" not in st.session_state:
    st.session_state["messages"] = []

# Mostrar historial de chat
for msg in st.session_state["messages"]:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# Entrada del usuario
user_input = st.chat_input("Haz tu pregunta sobre ahorro de agua...")

if user_input:
    # Mostrar mensaje del usuario en el chat
    st.session_state["messages"].append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    # Determinar si el usuario pregunta sobre su consumo
    if "consumo" in user_input.lower() and st.session_state["datos_consumo"]:
        prompt_chat = f"""
        Datos del hogar: {st.session_state["datos_consumo"]}
        An치lisis previo: {st.session_state["analisis_consumo"]}

        Usuario: {user_input}
        Asistente (responde en m치ximo 3 frases o en una lista de puntos, usando los datos proporcionados):"""
    else:
        prompt_chat = f"""
        Usuario: {user_input}
        Asistente (responde en m치ximo 3 frases o en una lista de puntos):"""

    # Generar respuesta con Watsonx
    with st.spinner("DeepWater est치 pensando..."):
        response = llm.invoke(prompt_chat)

    # Mostrar respuesta en el chat
    st.session_state["messages"].append({"role": "assistant", "content": response})
    with st.chat_message("assistant"):
        st.markdown(response)
